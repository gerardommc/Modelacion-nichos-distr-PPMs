Aquí veremos cómo se ajusta un proceso de puntos. Como vimos en el capítulo anterior, los datos que analizamos consisten de la intensidad de puntos por unidad espacial, como función de un conjunto de predictores.

Los modelos que ajustaremos son aquellos que propusimos como producto del análisis exploratorio del capítulo anterior. Para ajustar un proceso de puntos Poisson, utilizamos la función `ppm` (por "point process model") del paquete `spatstat`. Los argumentos que debemos incluir al llamar a la función son:

1. El objeto que contiene el proceso de puntos
2. `trend` que corresponde a la fórmula del modelo
3. La lista de imágenes de pixeles que contiene las covariables que se utilizan en la fórmula (con los mismos nombres)

Para ajustar el modelo propuesto con la 1a fórmula propuesta tenemos:

```{r echo = T, warning=FALSE, message=FALSE}
m1 <- ppm(Q = puntos.2.ppp,
          trend = ~ Var.1 + Var.3 + I(Var.1^2) + I(Var.3^2),
          covariates = s.im)
```

Para ver un resumen detallado del modelo ajustado, podemos utilizar la función `summary` del objeto creado `m1`, lo que imprimirá una tabla que muestra los coeficientes estimados, error para cada coeficiente, su significancia y otra información sobre el llamado a la función `ppm` y estadísticas de convergencia:

```{r}
summary(m1)
```

La parte del resumen del modelo ajustado que contiene los detalles de los coeficientes estimados es la que dice `Fitted trend coefficients`. La primera columna de esta tabla contiene los nombres de las variables, la segunda columna (`Estimates`) contiene el valor medio estimado de cada coeficiente. Las columnas 3-5 contienen el error estándar (`S.E.`), intervalo de confianza inferior y superior. La última columna (`Ztest`) contiene el valor de la probabilidad de que el intervalo a 95% contenga el valor de cero (0). Cuanto menos probable sea que contenga cero mejor.

Las predicciones del modelo podemos verlas con la función `plot`:

```{r echo = T, fig.align='center', fig.cap="Mapa de las predicciones del modelo. El panel izquierdo muestra la tendencia espacial y el derecho el error estándar de la tendencia estimada.", fig.width=8, fig.height=4}
par(mfrow = c(1, 2))
plot(m1)
```

### Selección del modelo

Ahora que ya sabemos ajustar un modelo, podemos proceder a ajustar los modelos de las fórmulas alternativas:

```{r echo = T, warning=FALSE}
m2 <- ppm(Q = puntos.2.ppp,
          trend = ~ Var.1 + Var.3 + I(Var.1^2) + I(Var.1^3) + I(Var.3^2),
          covariates = s.im)
m3 <- ppm(Q = puntos.2.ppp,
          trend = ~ Var.2 + Var.3 + I(Var.2^2) + I(Var.3^2),
          covariates = s.im)
```

El dilema con el que nos enfrentamos ahora es decidir con cuál modelo nos quedaremos. Hay una serie de criterios para tomar esta decisión que tienen que ver principalmente con:

1. El cumplimiento de los supuestos estadísticos (independencia de puntos y análisis de residuales)
2. El balance entre complejidad (cantidad de variables) y varianza explicada
3. Estimación correcta de los efectos (coeficientes) y su significancia

Como vimos anteriormente, el primer supuesto es que los puntos deben ser independientes, por lo que podemos simular envolturas de Ripley para los modelos ajustados, y los residuales podemos analizarlos visualmente. El balance entre la complejidad y la varianza explicada podemos calcularlo con el criterio de información de Akaike.

#### Criterio de información de Akaike

Calcular el AIC (por sus siglas en inglés), es muy fácil en R. Solamente necesitamos la función `AIC`, y proporcionarle los modelos cuyos criterios querramos conocer:

```{r echo = T}
AIC(m1)
AIC(m2)
AIC(m3)
```

La regla general es que cuanto más bajo sea el AIC, mejor, por lo que el modelo 3 (`m3`), parece tener la ventaja sobre el 1 y 2.

#### Estimación correcta de efectos

Dado que los MPPs son complejos es frecuente encontrarse con modelos que no pudieron ser ajustados correctamente, o sea que la rutina de optimización pudo encontrar los valores de los parámetros y calcular su significancia estadística. Por otra parte, cuando los efectos estadísticos pudieron ser calculados, nos interesa que la mayoría de estos sean significativamente diferentes de cero ($P \leq 0.05$)

Si revisamos el resumen del modelo `m2`, veremos que aparecen algunos de los errores mencionados, y que resultan en la ausencia de estimaciones de significancia estadística (columna `Ztest`).

```{r echo = T}
summary(m2)
```
En comparación, el resumen del modelo 3:

```{r echo = T}
summary(m3)
```

No tiene alertas de errores y sí imprime la columna de significancia estadística. Con esta simple verificación concluimos que `m3` es más adecuado que `m1` y `m2`, con base en los criterios:

1. Minimización de AIC
2. Estimación de efectos
3. Estimación de significancia estadística

Aún así, es posible que `m1` cumpla mejor con el criterio del supuesto de independencia, que veremos a continuación.

### Verificación de supuestos de independencia

Este criterio lo podemos verificar con dos pruebas adicionales:

1. Análisis de residuales
2. Simulación de envolturas *K*

#### Analisis de residuales

En las metodologias de regresion los efectos fijos se utilizan para explicar el comportamiento promedio de una variable aleatoria. Cuando la variable aleatoria tiene una distribucion normal y calculamos la media aritmetica: 

\begin{equation}
\mu_X = \sum \frac{x_i}{n}
\end{equation}

y despues restamos la media aritmetica a cada uno de los valores de $X$, el resultado es la misma variable con distribucion normal pero con media de cero. Para ilustrar esto, simulemos una variable de diez valores con media de 5 y desviacion estandar de 2:

```{r echo = T}
x <- rnorm(10, mean = 5, sd = 2); x
```

verificamos la media:

```{r}
mean(x)
```

Para mostrar la distribucion de la variable tambien la podemos graficar e indicar donde queda la media estimada:

```{r fig.height=4, fig.width=4}
plot(density(x), main = "Densidad de x", col = "red")
abline(v = mean(x), lty = 3, col = "red")
```

El efecto de restar la media a todos los valores de $x$ se muestra a continuacion

```{r normal-cent, echo=T, fig.height=4, fig.width=4}
x.0 <- x - mean(x)
plot(density(x.0), col = "red", main = "Densidad de x.0")
abline(v = mean(x.0), lty = 3, col = "red")
```

Para mostrar mas objetivamente que ambas variables tienen una distribucion normal tambien podemos hacer:

```{r echo = T}
shapiro.test(x)
shapiro.test(x.0)
```

De igual manera que como acabamos de hacer al restar la media de toda la variable $x$ los residuals se obtienen restando las predicciones de un modelo (lineal o de puntos, p. ej.) se restan a todos los valores de la variable dependiente. Por ejemplo, vamos a simular otras dos variables $x$ y $y$, de modo que:

$$ y(x) = \alpha + \beta x$$
$y$ sea una funcion de $x$.

```{r echo= T, fig.height=4, fig.width=4}
x <- rnorm(100)
y <- rnorm(100, 10, 1) + runif(1, 2, 3) * x
plot(x, y, main = "", col = "red")
```

Ajustaremos el modelo lineal para estimar a $\alpha$ y $\beta$, y extraer los residuales:

```{r echo = T}
mod.lin <- lm(y~x)
resids <- residuals(mod.lin)
predics <- predict(mod.lin)
```
 
y veremos como $\varepsilon = y - y(x)$

```{r echo = T}
df <- data.frame(y = y, predicciones = predics, residuales = resids)
knitr::kable(head(df))
```

puesto que $y(x_i)$ es la media de $y_i$ para $x_i$. De modo que del mismo modo que con la figura \@ref(fig:normal-cent), los residuales $\varepsilon$ tienen una distribucion normal con media de cero (0):

```{r fig.height=4, fig.width=4}
plot(density(df$residuales), col = "red", main = "Residuales")
abline(v = mean(df$residuales), lty = 3, col = "red")
```

En el caso de los procesos de puntos los residuales tambien deben tener una media de cero, y ser aproximadamente normales (con varianza homogenea).

A diferencia de los procedimientos de regresión lineal, los procesos de puntos no se limitan al análisis de las coordenadas del fenómeno que estamos estudiando, si no a todas las unidades espaciales donde podría estar definido el proceso de puntos. Esto implica que tenemos que evaluar los residuales en el espacio. aquí surge una pregunta muy natural, ¿cómo se evalúan los residuales de una serie de puntos discretos en una rejilla de unidades espaciales? El paquete `spatstat` emplea un método muy ingenioso que consiste en:

1. Generación de un mapa de densidad del procesos de puntos analizado con una estimación de kernel
2. Calcular la diferencia entre la densidad estimada con el modelo y la de kernel
3. Suavizar la diferencia, promediando unidades espaciales adyacentes con una distancia similar a la utilizada en la estimación de kernel
4. Sumar los residuales en las dimensiones $x$ y $y$

El resultado de este procedimiento se llama *lurking plot*. La función para hacer este análisis es `diagnose.ppm`:

```{r diag, echo=T, fig.height=5, fig.width=5, fig.align='center', fig.cap="Gráfico de residuales suavizados del modelo 3."}
par(mar = c(2,2,2,2))
diagnose.ppm(m3)
```

El primer panel (arriba, izquierdo) de este gráfico muestra el proceso de puntos analizado, seguido a la derecha, de los residuales acumulados en el eje de las $y$. En el panel de abajo a la izquierda se muestran los residuales acumulados en el eje de las $x$ y en el panel de abajo a la derecha, se muestran los residuales. En un escenario ideal, este último panel debe mostrar valores muy cercanos a cero. Las líneas punteadas que rodean a la suma de residuales son los límites de tolerancia que no deben ser excedidos por los residuales para cumplirse el supuesto de aleatoriedad de los residuales. Como resulta evidente, los residuales en $y$ exceden el límite de tolerancia en una región.

#### Simulación de envolturas de Ripley

Como vimos en el análisis exloratorio, podemos medir la autocorrelación para ver si de antemano necesitamos tomarla en cuenta para el análisis. La prueba que hicimos fue la de Ripley, comparando el número promedio de vecinos en función de un radio al rededor de cada punto. Aún cuando un proceso de puntos Poisson asume que los puntos son independientes entre sí, es posible que cuando detectamos autocorrelación con la prueba de Ripley, podamos generar un modelo Poisson que explique el patrón de puntos por medio de covariables. Para ver si el modelo que formulamos en efecto explica la autocorrelación, podemos usarlo para simular patrones de puntos y comparalos con la expectativa teórica.

Para hacer esta comparación utilizamos la misma función que antes, pero el primer argumento es el objeto que contiene el modelo que queremos analizar. Comparemos en esta ocasión los tres modelos:

```{r echo = T, message = F, warning=F}
K1 <- envelope(m1, Kest, nsim = 39)
K2 <- envelope(m2, Kest, nsim = 39)
K3 <- envelope(m3, Kest, nsim = 39)
```

```{r K-modelos, echo=T, fig.height=4, fig.width=12, fig.align='center', fig.cap="Gráficas de las envolturas de Ripley."}
par(mfrow = c(1, 3))
plot(K1); plot(K2); plot(K3)
```

Todos los modelos muestran un comportamiento adecuado, aunque `m3` parece estar marginalmente más cerca de la expectativa teórica (en rojo), sin ser significativo.