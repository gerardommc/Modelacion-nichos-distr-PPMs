Aquí veremos cómo se ajusta un proceso de puntos. Como vimos en el capítulo anterior, los datos que analizamos consisten de la intensidad de puntos por unidad espacial, como función de un conjunto de predictores.

Los modelos que ajustaremos son aquellos que propusimos como producto del análisis exploratorio del capítulo anterior. Para ajustar un proceso de puntos Poisson, utilizamos la función `ppm` (por "point process model") del paquete `spatstat`. Los argumentos que debemos incluir al llamar a la función son:

1. El objeto que contiene el proceso de puntos
2. `trend` que corresponde a la fórmula del modelo
3. La lista de imágenes de pixeles que contiene las covariables que se utilizan en la fórmula (con los mismos nombres)

Para ajustar el modelo propuesto con la 1a fórmula propuesta tenemos:

```{r echo = T, warning=FALSE, message=FALSE}
m1 <- ppm(Q = puntos.2.ppp,
          trend = ~ Var.1 + Var.3 + I(Var.1^2) + I(Var.3^2),
          covariates = s.im)
```

Para ver un resumen detallado del modelo ajustado, podemos utilizar la función `summary` del objeto creado `m1`, lo que imprimirá una tabla que muestra los coeficientes estimados, error para cada coeficiente, su significancia y otra información sobre el llamado a la función `ppm` y estadísticas de convergencia:

```{r}
summary(m1)
```

La parte del resumen del modelo ajustado que contiene los detalles de los coeficientes estimados es la que dice `Fitted trend coefficients`. La primera columna de esta tabla contiene los nombres de las variables, la segunda columna (`Estimates`) contiene el valor medio estimado de cada coeficiente. Las columnas 3-5 contienen el error estándar (`S.E.`), intervalo de confianza inferior y superior. La última columna (`Ztest`) contiene el valor de la probabilidad de que el intervalo a 95% contenga el valor de cero (0). Cuanto menos probable sea que contenga cero mejor.

Las predicciones del modelo podemos verlas con la función `plot`:

```{r echo = T, fig.align='center', fig.cap="Mapa de las predicciones del modelo. El panel izquierdo muestra la tendencia espacial y el derecho el error estándar de la tendencia estimada.", fig.width=8, fig.height=4}
par(mfrow = c(1, 2))
plot(m1)
```

### Selección del modelo

Ahora que ya sabemos ajustar un modelo, podemos proceder a ajustar los modelos de las fórmulas alternativas:

```{r echo = T, warning=FALSE}
m2 <- ppm(Q = puntos.2.ppp,
          trend = ~ Var.1 + Var.3 + I(Var.1^2) + I(Var.1^3) + I(Var.3^2),
          covariates = s.im)
m3 <- ppm(Q = puntos.2.ppp,
          trend = ~ Var.2 + Var.3 + I(Var.2^2) + I(Var.3^2),
          covariates = s.im)
```

El dilema con el que nos enfrentamos ahora es decidir con cuál modelo nos quedaremos. Hay una serie de criterios para tomar esta decisión que tienen que ver principalmente con:

1. El cumplimiento de los supuestos estadísticos (independencia de puntos y análisis de residuales)
2. El balance entre complejidad (cantidad de variables) y varianza explicada
3. Estimación correcta de los efectos (coeficientes) y su significancia

Como vimos anteriormente, el primer supuesto es que los puntos deben ser independientes, por lo que podemos simular envolturas de Ripley para los modelos ajustados, y los residuales podemos analizarlos visualmente. El balance entre la complejidad y la varianza explicada podemos calcularlo con el criterio de información de Akaike.

#### Criterio de información de Akaike

Calcular el AIC (por sus siglas en inglés), es muy fácil en R. Solamente necesitamos la función `AIC`, y proporcionarle los modelos cuyos criterios querramos conocer:

```{r echo = T}
AIC(m1)
AIC(m2)
AIC(m3)
```

La regla general es que cuanto más bajo sea el AIC, mejor, por lo que el modelo 3 (`m3`), parece tener la ventaja sobre el 1 y 2.

#### Estimación correcta de efectos

Dado que los MPPs son complejos es frecuente encontrarse con modelos que no pudieron ser ajustados correctamente, o sea que la rutina de optimización pudo encontrar los valores de los parámetros y calcular su significancia estadística. Por otra parte, cuando los efectos estadísticos pudieron ser calculados, nos interesa que la mayoría de estos sean significativamente diferentes de cero ($P \leq 0.05$)

Si revisamos el resumen del modelo `m2`, veremos que aparecen algunos de los errores mencionados, y que resultan en la ausencia de estimaciones de significancia estadística (columna `Ztest`).

```{r echo = T}
summary(m2)
```
En comparación, el resumen del modelo 3:

```{r echo = T}
summary(m3)
```

No tiene alertas de errores y sí imprime la columna de significancia estadística. Con esta simple verificación concluimos que `m3` es más adecuado que `m1` y `m2`, con base en los criterios:

1. Minimización de AIC
2. Estimación de efectos
3. Estimación de significancia estadística

Aún así, es posible que `m1` cumpla mejor con el criterio del supuesto de independencia, que veremos a continuación.

#### Verificación de supuestos de independencia

Este criterio lo podemos verificar con dos pruebas adicionales:

1. Análisis de residuales
2. Simulación de envolturas *K*

##### Analisis de residuales

En las metodologias de regresion los efectos fijos se utilizan para explicar el comportamiento promedio de una variable aleatoria. Cuando la variable aleatoria tiene una distribucion normal y calculamos la media aritmetica: 

\begin{equation}
\mu_X = \sum \frac{x_i}{n}
\end{equation}

y despues restamos la media aritmetica a cada uno de los valores de $X$, el resultado es la misma variable con distribucion normal pero con media de cero. Para ilustrar esto, simulemos una variable de diez valores con media de 5 y desviacion estandar de 2:

```{r echo = T}
x <- rnorm(10, mean = 5, sd = 2); x
```

verificamos la media:

```{r}
mean(x)
```

Para mostrar la distribucion de la variable tambien la podemos graficar e indicar donde queda la media estimada:

```{r fig.height=4, fig.width=4}
plot(density(x), main = "Densidad de x", col = "red")
abline(v = mean(x), lty = 3, col = "red")
```

El efecto de restar la media a todos los valores de $x$ se muestra a continuacion

```{r normal-cent, echo=T, fig.height=4, fig.width=4}
x.0 <- x - mean(x)
plot(density(x.0), col = "red", main = "Densidad de x.0")
abline(v = mean(x.0), lty = 3, col = "red")
```

Para mostrar mas objetivamente que ambas variables tienen una distribucion normal tambien podemos hacer:

```{r echo = T}
shapiro.test(x)
shapiro.test(x.0)
```

De igual manera que como acabamos de hacer al restar la media de toda la variable $x$ los residuals se obtienen restando las predicciones de un modelo (lineal o de puntos, p. ej.) se restan a todos los valores de la variable dependiente. Por ejemplo, vamos a simular otras dos variables $x$ y $y$, de modo que:

$$ y(x) = \alpha + \beta x$$
$y$ sea una funcion de $x$.

```{r echo= T, fig.height=4, fig.width=4}
x <- rnorm(100)
y <- rnorm(100, 10, 1) + runif(1, 2, 3) * x
plot(x, y, main = "", col = "red")
```

Ajustaremos el modelo lineal para estimar a $\alpha$ y $\beta$, y extraer los residuales:

```{r echo = T}
mod.lin <- lm(y~x)
resids <- residuals(mod.lin)
predics <- predict(mod.lin)
```
 
y veremos como $\varepsilon = y - y(x)$

```{r echo = T}
df <- data.frame(y = y, predicciones = predics, residuales = resids)
knitr::kable(head(df))
```

puesto que $y(x_i)$ es la media de $y_i$ para $x_i$. De modo que del mismo modo que con la figura \@ref(fig:normal-cent), los residuales $\varepsilon$ tienen una distribucion normal con media de cero (0):

```{r fig.height=4, fig.width=4}
plot(density(df$residuales), col = "red", main = "Residuales")
abline(v = mean(df$residuales), lty = 3, col = "red")
```

En el caso de los procesos de puntos los residuales tambien deben tener una media de cero, y ser aproximadamente normales (con varianza homogenea).