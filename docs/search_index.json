[["index.html", "Modelación de nichos ecológicos y aŕeas de distribución con MPPs 1 Preámbulo", " Modelación de nichos ecológicos y aŕeas de distribución con MPPs Gerardo Martín 2022-04-06 1 Preámbulo En este curso aprenderemos a utilizar algunas herramientas para el análisis de datos de ocurrencia geográfica de especies y desarrollar lo que en ecología se llama Modelos de nicho ecológico y de Distribución geográfica de especies. "],["encuadre-de-la-materia.html", " 2 Encuadre de la materia 2.1 Criterios de evaluación 2.2 ¿Cómo se darán las clases? 2.3 Contacto", " 2 Encuadre de la materia 2.1 Criterios de evaluación Las constribuciones a cada calificación parcial serán: Asistencia (25%) Trabajos de clase cumplidos (50%) Examen (25%) Participación (2 puntos extra máximo) Cabe señalar, que la asistencia no corresponderá con su presencia en las sesiones sincrónicas, sino con el cumplimiento de los trabajos de clase. La participación se medirá tanto por participación directa en las sesiones sincrónicas como por el seguimiento que uds den a la clase por correo electrónico. 2.2 ¿Cómo se darán las clases? Todos los contenidos del curso, lecturas y presentaciones, se irán añadiendo a este sitio web conforme avanza el semestre. En el Google Classroom de la materia se irán anunciando las diferentes actividades y sesiones sincrónicas con anticipación suficiente. Igualmente, los examenes y resultados serán publicados a través de esta plataforma. A petición de uds, también se publicarán aquí los videos de las sesiones sincrónicas que tengamos, en especial para aquellos temas que sean mayor interés/dificultad/importancia. Los trabajos de práctica también se publicarán en Classroom. 2.3 Contacto Para reportar fallos, resolver dudas y peticiones especiales grupales o individuales por favor enviar correo electrónico a gerardo.mmc@enesmerida.unam.mx. "],["unidad-i-introducción-al-modelado-de-procesos-de-puntos.html", " 3 Unidad I: Introducción al modelado de procesos de puntos 3.1 Introducción 3.2 Formateo de datos", " 3 Unidad I: Introducción al modelado de procesos de puntos 3.1 Introducción Cuando analizamos datos con alguna metodología de regresión siempre tenemos claro cuál es la variable de respuesta. Por ejemplo, en un análisis de temperaturas como función de la elevación sobre el nivel del mar y la latitud, el modelo ajustado arrojará valores en las unidades \\(°\\mathrm{C}\\), o las que hayamos utilizado. Aunque la modelación correlativa de nichos esté en gran medida basada en la modelación estadística, ha prevalecido una desconexión sustancial entre lo que se modela y lo que los modelos estadísticos arrojan. La herramienta estadística de regresión que resuelve en buena medida esta desconexión son los Modelos de Procesos de Puntos (MPPs). En MPPs, la variable analizada es la intensidad de puntos, por lo que un MPP predice intensidad. Los datos de sólo presencia de especies pueden ser concebidos de manera más general como un proceso de puntos (la colección de coordenadas a modelar) sobre una rejilla de unidades espaciales de tamaño fijo. Con esto en mente, la intesidad se define como el número promedio de puntos por unidad espacial. Existe una variedad de MPPs, pero el que estudiaremos aquí son los MPPs Poisson. En estos, la variable intensidad es modelada como una función log-lineal de la distribución Poisson (para conteos), de un conjunto de covariables ambientales. Por lo tanto, los MPPs Poisson son muy similares a los modelos lineales generalizados. Estos métodos tienen ya una larga trayectoria en estadística espacial y geoestadística, para el análisis de variables aleatorias definidas en el espacio. Muchos de estos métodos existen incluso antes que algunos métodos utilizados rutinariamente para la generación de modelos de nicho ecológico o áreas de distribución. De hecho, un análisis matemático de 2013, encontró que Maxent es en esencia un MPP Poisson. Para aprender a analizar conjuntos de puntos de ocurrencia utilizaremos el programa R y el paquete spatstat, principalmente. En esta unidad introductoria, aprenderemos a formatear los datos de ocurrencia y las variables ambientales para que puedan ser utilizadas por spatstat. Posteriormente veremos cómo se hace un análisis exploratorio para identificar las variables que potencialmente explican los patrones de intensidad de puntos de nuestra base de datos. Finalmente, veremos cómo se ajusta, selecciona y diagnostica estadísticamente un MPP Poisson. Cabe mencionar que aquí nos enfocaremos en el aspecto técnico-metodológico, aunque los conceptos como área de accesibilidad, modelo de nicho vs. modelo de distribución siguen aplicandose como en cualquier otra herramienta para el análisis de nichos ecológicos y distribuciones geográficas. 3.2 Formateo de datos Los formatos básicos en que podemos tener almacenados los datos son los tradicionales .csv, para las ocurrencias, y .tif para los raster. La razón principal por la que se necesita un formato especial para los datos es que spatstat utiliza objetos de clase im o imágenes en lugar de raster, un patrón plano de puntos, objetos de clase ppp para los datos de ocurrencia, que normalmente se manejan como un data.frame, y una ventana de trabajo que es obtiene a partir de los raster. Hacer la transformación entre formatos es esencial pues spatstat cuenta con muchas funciones para hacer del análisis de datos en estos formatos bastante sencillo. 3.2.1 Formateo de datos raster He escrito una función de R para transformar de raster a im. La transformación de un data.frame a ppp es bastante sencilla y no requiere de una función especial. Entonces, para comenzar necesitamos tener instalados los paquetes raster, rgdal, spatstat y foreach, lo cual se consigue corriendo el siguiente código en la consola de R: install.packages(c(&quot;raster&quot;, &quot;rgdal&quot;, &quot;spatstat&quot;, &quot;foreach&quot;)) Después de la instalación, podemos usarlos para cargar una sola capas raster al espacio de trabajo con la función raster, contenida en el paquete del mismo nombre: library(raster); library(spatstat) r &lt;- raster(&quot;../Datos-ejemplos/Var-1.tif&quot;) El único argumento que se pasa a la función raster es la ruta y nombre del archivo. En este caso el archivo está en la carpeta \"Datos-ejemplos\", y el archivo se llama Var-1.tif. Es importante siempre incluir la extensión del archivo (las 2-4 letras después del punto). En caso de necesitar cargar más de un archivo al mismo tiempo, podemos utilizar la función stack. Aquí es importante señalar que para que esta función pueda cargar los archivos, estos tienen que estar perfectamente alineados y tener exactamente la misma extensión espacial. El argumento que tenemos que pasar a la función stack es la lista de archivos a leer. Esta podemos generarla automáticamente con la función list.files, cuyos argumentos son la carpeta de búsqueda, extensión de los archivos a listar, y si necesitamos la ruta completa junto con los nombres de los archivos: arch &lt;- list.files(&quot;../Datos-ejemplos/&quot;, &quot;.tif&quot;, full.names = T) s &lt;- stack(arch) Una vez cargados las capas, podemos graficarlas para verificar que sean las que necesitamos o tenemos en mente: plot(s) Figura 3.1: Gráfica de las capas que usaremos para los ejemplos. La transformación a im la haremos solo con el stack, pues es el escenario más probable al que se encontrarán (trabajo con varias capas). Comenzaremos cargando la función para hacer la transformación, que se llama imFromStack. Para hacerlo utilizaremos la función source, y el argumento que necesita es la ruta y nombre del archivo de texto que contiene la función: source(&quot;../Funciones-spatstat/imFromStack.R&quot;) Una vez cargada, podemos utilizarla, pasando como únigo argumento el nombre del objeto en el espacio de trabajo de R que contiene las capas: s.im &lt;- imFromStack(s) Para verificar el tipo de objeto que resulta, podemos correr la función: class(s.im) ## [1] &quot;list&quot; Como podemos ver es una lista, y cada uno de sus elementos es una imagen tipo im: class(s.im[[1]]) ## [1] &quot;im&quot; Podemos hacer la gráfica, aunque ahora tenemos que hacerlo una por una: par(mfrow = c(2, 2)) plot(s.im[[1]]) plot(s.im[[2]]) plot(s.im[[3]]) Puedes descargar la función imFromStack en esta liga. 3.2.2 Obteniendo la ventana de trabajo Antes de continuar, considero importante establecer que el método de obtención de la ventana de trabajo que he implementado asume que el área de accesibilidad de la especie de análisis es toda la extensión del raster que se utilice para obtener la ventana del área de trabajo. La función para obtener la ventana de trabajo a partir de un raster es winFromRaster (disponible aquí), y la importamos del mismo modo que imFromStack: source(&quot;../Funciones-spatstat/winFromRaster.R&quot;) win &lt;- winFromRaster(s) class(win) ## [1] &quot;owin&quot; 3.2.3 Formateando los registros de ocurrencia Primero, necesitamos contar con una base de datos de ocurrencia, en esta ocasión por tratarse de una un ejemplo de formateo, simularé una con la función randomPoints del paquete dismo, y solo para hacerla un poco más interesante le voy a añadir ruido con una distribución normal a las coordenadas \\(x, y\\): puntos &lt;- data.frame(dismo::randomPoints(s, 200)) puntos$x &lt;- puntos$x + rnorm(200, 0, 0.05) puntos$y &lt;- puntos$y + rnorm(200, 0, 0.05) Ahora bien, para transformar el objeto puntos de un data.frame a ppp utilizaremos pa función del mismo nombre, y la ventana de trabajo que creamos arriba: puntos.ppp &lt;- ppp(x = puntos$x, y = puntos$y, window = win, check = F) class(puntos.ppp) ## [1] &quot;ppp&quot; En el primer argumento x se especifican las coordenadas \\(x\\) o longitud, en y las coordenadas \\(y\\) o latitud, en window la ventana de trabajo, y check especifica si se verificará que todos los puntos están dentro de la ventana de trabajo. Normalmente se deja en check = T. Con todos los datos formateados, entonces ahora graficamos la ventana de trabajo y el proceso de puntos: plot(win); points(puntos.ppp, col = &quot;white&quot;) "],["unidad-ii-utilizando-spatstat.html", " 4 Unidad II - Utilizando spatstat 4.1 Análisis exploratorio", " 4 Unidad II - Utilizando spatstat 4.1 Análisis exploratorio Antes de proponer un modelo para los datos de ocurrencia, es buena práctica realizar un análisis exploratorio. En realidad, el modelo que propongamos dependerá en buena medida de este análisis exploratorio. Los análisis exploratorios que yo hago comprenden una serie de pasos: Probar si los datos de ocurrencia cumplen son independientes unos de otros o si están autocorrelacionados Ver la respuesta de la intensidad de puntos ante las diferentes variables ambientales que queremos incorporar en el modelo Medir la correlación entre las diferentes variables Con base en los puntos 2 y 3 proponer un conjunto de modelos alternativos (más sobre este punto abajo) 4.1.1 Independencia y autocorrelación Se dice que los diferentes puntos son independientes entre sí, si el número de vecinos promedio de cada punto como función de la distancia, sigue una distribución Poisson (figura 4.1). Con esto en mente hay varios escenarios posibles, que en promedio cada punto tenga más vecinos de lo esperado o que tenga menos. En el primer caso, se dice que los puntos están agregados, pues un punto tiende a atraer a otros. En el segundo, los puntos están segregados, o sea que un punto tiende a mantener a otros puntos lejos de sí. El primer caso, de independencia, suele ocurrir cuando los puntos están distribuidos aleatoriamente (figura 4.2). Figura 4.1: Número de vecinos como función de la distancia en un proceso de puntos. Figura 4.2: Ejemplo de procesos de puntos de izquierda a derecha: segregado, aleatorio y agregado (reproducido de Baddeley y Rubak 2016) Existe una serie de pruebas gráficas y estadísticas para medir autocorrelación. Aquí nos enfocaremos en el uso de la prueba de envolturas K de Ripley. La implementación de esta prueba en spatstat genera unos intervalos de confianza alrededor de la expectativa del número de vecinos por medio de simulación. La figura 4.3 muestra los tres escenarios de segregación, aleatorio y agrecación. Figura 4.3: Gráfica de la prueba K de Ripley implementada en spatstat. De izquierda a derecha: funciones de Ripley para puntos segregados, aleatorios y agregados. 4.1.1.1 Análisis de autocorrelación en R con spatstat Haremos este análisis de autocorrelación con el mismo proceso de puntos que formateamos anteriormente. La función de spatstat para la prueba de Ripley es envelope, y los argumentos que requiere son 1) el proceso de puntos a analizar, 2) la función con que se medirá autocorrelación (Kest para \\(K\\) de Ripley) y 3) el número de simulaciones. Normalmente, para un nivel de significancia \\(P=0.05\\), se utilizan 39 simulaciones, el cual deberá aumentar si el umbral de significancia buscado es más estricto (\\(P = 0.01\\), p. ej.). K &lt;- envelope(puntos.ppp, fun = Kest, nsim = 39) ## Generating 39 simulations of CSR ... ## 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39. ## ## Done. Mientras la función corre, R imprime la última simulación completada, y el objeto que se obtiene puede graficarse con el método por defecto plot: plot(K) Figura 4.4: Gráfica de la función K de Ripley para el proceso de puntos analizado. Las sombras en gris muestran los intervalos de confianza al 95%. La línea roja a guiones representa la expectativa teórica (K teórica) en caso de que el proceso de puntos sea aleatorio, y la línea negra sólida es la función de Ripley para el proceso de puntos (la K observada). El eje de las x representa distancia (en grados) y las y el número promedio de vecinos de cada punto. 4.1.2 Análisis gráfico de las respuestas al medio ambiente. Para este análisis simularé una base de datos de ocurrencia donde la probabilidad de observarlos sea inversamente proporcional a la distancia de una centroide pre definido. Con base en ello, podremos ver cómo cambia la intensidad de puntos en realción a los diferentes valores de cada variable. 4.1.2.1 Simulación de datos de presencia Utilizaré las mismas variables que para el ejercicio anterior de formateo, y el centroide estará localizado en la media aritmética de cada capa: centroide &lt;- cellStats(s, mean) Para calcular la distancia al centroide, necesitamos la covarianza entre las diferentes capas, de modo que la calculamos con la función cov. Hay implementaciones más robustas en el paquete MASS, para nuestros propósitos pedagógicos cov es suficiente. Comenzamos entonces, transformando el stack en una tabla: s.df &lt;- data.frame(rasterToPoints(s)) covar &lt;- cov(s.df[, 3:5]) Posteriormente, utilizando el centroide y la matriz de covarianza, generamos las distancias utilizando las tres columnas del objeto s.df que contienen los valores de las variables ambientales: md &lt;- mahalanobis(s.df[, 3:5], center = centroide, cov = covar) Y transformamos las distancias al centroide en una capa raster: md.r &lt;- rasterFromXYZ(data.frame(s.df[, 1:2], md)) plot(md.r) Figura 4.5: Distancia Mahalanobis al centroide de las capas. Para simular las ocurrencias, transformaré la capa de distancias exponencialmente, para obtener una superficie probabilística: md.exp &lt;- exp(-0.5*md.r) plot(md.exp) Figura 4.6: Distancia Mahalanobis transformada exponencialmente para simular presencias. Verde indica mayor probabilidad de ocurrencia. Para simular las presencias usaré el mismo método que anteriormente, pero en esta ocasión la probabilidad determinará las celdas en que habrá puntos: puntos.2 &lt;- dismo::randomPoints(mask = md.exp, n = 200, prob = T) ## Warning in if (class(cells) == &quot;try-error&quot;) {: la condición tiene longitud &gt; 1 ## y sólo el primer elemento será usado ## Warning in .couldBeLonLat(x, warnings = warnings): CRS is NA. Assuming it is ## longitude/latitude puntos.2 &lt;- data.frame(puntos.2) puntos.2$x &lt;- puntos.2$x + rnorm(200, 0, 0.05) puntos.2$y &lt;- puntos.2$y + rnorm(200, 0, 0.05) plot(md.exp); points(puntos.2) #### Graficación y análisis de las respuestas Para continuar con el análisis, necesitamos formatear el objeto puntos.2 como ppp: puntos.2.ppp &lt;- ppp(x = puntos.2$x, y = puntos.2$y, window = win, check = F) Recordemos que el objeto win lo generamos en la sección de formateo de este tutorial. Para el análisis de las respuestas necesitamos crear otro objeto, que contiene los conteos de cuadratura, es decir, cuántas presencias por unidad espacial, con la función pixelquad que requiere de dos argumentos, el proceso planar de puntos y la ventana de trabajo en formato owin: Q &lt;- pixelquad(X = puntos.2.ppp, W = as.owin(win)) Dado que las capas ya están también formateadas como im, podemos ahora sí continuar con el análisis de las respuestas con la función plotQuantIntens. Esta función generará unos gráficos en pdf que deberemos revisar después de correrla. Para cargar la función, haremos igual que con las anteriores. Puedes descargar la función aquí. Esta función requiere de varios argumentos: La lista de imágenes que se usarán para ver cómo cambia la intensidad de puntos en relación a cada variable El número de cuantiles en que se cortará cada variable para representar la intensidad en el espacio El objeto de cuadratura (Q) El objeto con los puntos en formato ppp El nombre del directorio donde se guardará el archivo pdf El nombre del archivo source(&quot;../Funciones-spatstat/plotQuantIntens.R&quot;) plotQuantIntens(imList = s.im, noCuts = 5, Quad = Q, p.pp = puntos.2.ppp, dir = &quot;&quot;, name = &quot;Responses-centroid.pdf&quot;) ## png ## 2 El archivo de gráficas que produce plotQuantIntens muestra en cada panel: La variable analizada con el número de puntos en cada región de varlores especificada por el argumento noCuts o nombre de cortes La variable analizada y el proceso de puntos La respuesta de la intensidad de puntos a la variable analizada. En el eje de las \\(x\\) (horizontal), el valor de la variable, y en el eje de las \\(y\\) la intensidad de puntos. La idea de este análisis es que podamos identificar a priori qué variables podemos incluir en el modelo y con qué tipo de relación. Por ejemplo, las variables 2 y 3 tienen respuestas claramente de una parácola invertida o de campana, por lo que podemos utilizar una fórmula polinomial de \\(2^o\\) grado (figura 4.7). Para la variable 1, no hay una respuesta clara como con las variables 2 y 3. Sin embargo, dado que la intensidad de puntos tiende a aumentar después de disminuir alrededor del valor de 190 conforme la variable aumenta podríamos utilizar un término cúbico, pues una ecuación cúbica puede adquirir esta forma (figura 4.8). curve(exp(1 + x - x^2), from = -3, 3) Figura 4.7: Ecuación polinomial de 2o grado exponenciada. Por otro lado, una ecuación polinomial de \\(3^{er}\\) grado: curve(exp(1+ x - 2*x^2 + x^3), from = -1.5, to = 1.4 ) Figura 4.8: Ecuación polinomial de 3er grado exponenciada. "],["references.html", "References", " References "]]
