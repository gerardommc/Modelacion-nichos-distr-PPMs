[["index.html", "Análisis y Modelado Espacial 1 Preámbulo", " Análisis y Modelado Espacial Gerardo Martín 2022-03-14 1 Preámbulo En el curso Modelado y Análisis Espacial aprenderemos a utilizar algunas herramientas para aprender a usar herramientas geográficas para analizar y representar procesos ambientales en el espacio. Los contenidos del índice se apegan al programa completo del curso, el cual se impartirá en los horarios normales establecidos. Para conocer cuándo, cómo y qué temas se se impartirán puedes consultar la estrategia docente. "],["encuadre-de-la-materia.html", " 2 Encuadre de la materia 2.1 Criterios de evaluación 2.2 ¿Cómo se darán las clases? 2.3 Reglas del salón 2.4 Contacto", " 2 Encuadre de la materia 2.1 Criterios de evaluación Las constribuciones a cada calificación parcial serán: Asistencia (25%) Trabajos de clase cumplidos (50%) Examen (25%) Participación (2 puntos extra máximo) Cabe señalar, que la asistencia no corresponderá con su presencia en las sesiones sincrónicas, sino con el cumplimiento de los trabajos de clase. La participación se medirá tanto por participación directa en las sesiones sincrónicas como por el seguimiento que uds den a la clase por correo electrónico. 2.2 ¿Cómo se darán las clases? Trataré de apegarnos a los tiempos de actividades sincrónicas y asincrónicas establecidos en la estrategia docente, pero éstos son completamente flexibles. Una estrategia que me ha funcionado en cursos anteriores ha sido la de dedicar la última actividad sicrónica de la semana a resolver dudas, es en estas sesiones en las que hay muchas posibilidades de conseguir puntos de participación. Todos los contenidos del curso, lecturas y presentaciones, se irán añadiendo a este sitio web conforme avanza el semestre. En el Google Classroom de la materia se irán anunciando las diferentes actividades y sesiones sincrónicas con anticipación suficiente. Igualmente, los examenes y resultados serán publicados a través de esta plataforma. A petición de uds, también se publicarán aquí los videos de las sesiones sincrónicas que tengamos, en especial para aquellos temas que sean mayor interés/dificultad/importancia. Los trabajos de práctica también se publicarán en Classroom. Para finalizar, las clases sincrónicas estarán almacenadas en la playlist de la clase contenida en mi canal de youtube. 2.3 Reglas del salón Estas, obviamente, son particulares del modelo en línea, por lo tanto aquí van las reglas de zoom: Micrófonos apagados Cámaras prendidas, exceptuando: 2.1. Si su velocidad de internet lo dificulta 2.2. Si tienen datos limitados Hacer muchas preguntas Decirme si paso algo por alto 2.4 Contacto Para reportar fallos, resolver dudas y peticiones especiales grupales o individuales por favor enviar correo electrónico a gerardo.mmc@enesmerida.unam.mx. "],["unidad-i-introducción-al-modelado-espacial.html", " 3 Unidad I: Introducción al modelado espacial 3.1 Análisis utilizando sistemas de información geográfica 3.2 Modelado espacial", " 3 Unidad I: Introducción al modelado espacial 3.1 Análisis utilizando sistemas de información geográfica 3.1.1 Introducción En el mundo moderno hay una gran cantidad de procesos y servicios que utilizan información espacial. Más allá de las aplicaciones comerciales que ya todxs conocemos hoy por hoy, los sistemas de información geográficas (SIG) son altamente necesarios para planear muchas de las actividades de las sociedades, por ejemplo para identificar áreas: donde se permitirá la urbanización prioritarias de conservación donde se puede practicar la agricultura donde se puede producir energías renovables que se pueden ver afectadas por desastres naturales Además de identificación de zonas relevantes, también sirven para la cuantificación tanto de superficies como de poblaciones humanas. En ciencas ambientales, nos interesaría aprender a utilizar los SIG para solventar problemáticas ambientales sobretodo aquellas resultado de las actividades del ser humano. Las soluciones ambientales requieren tanto de la identificación espacial como del monitoreo, manejo y mitigación, cuyo éxito puede depender en gran medida de la disponibilidad de información geográfica. 3.1.2 Ejercicio Visita la página del Socioeconomic Data and Applications Center y navega por los diferentes apartados temáticos que cubren, haciendo una lista con descripciones de mapas que te parezcan interesantes o relevantes. 3.1.3 ¿Qué son los SIG? Los SIG son programas de computadora especializados en el manejo, análisis y visualización de datos geográficos. Estos últimos a grandes rasgos con una descripción numerica o cualitativa que esté georreferenciada, o bien, que represente la forma o algún atributo de un objeto cuya localización se conoce. Los sistemas de información geográfica por lo general utilizan distintos tipo de datos. 3.1.3.1 Imágenes ráster Consisten de píxeles que representan valores con alguna paleta de colores Figura 3.1: Ejemplo de capa ráster de algún atributo ambiental de la isla de Sri Lanka. Cada píxel mide 5 x 5 km. 3.1.3.2 Capas vectoriales Pueden representar tanto polígonos como líneas. Los polígonos son utilizados para representar entidades políticas como los países o estados. Las capas vectoriales de líneas pueden utilizarse para representar ríos o caminos ## OGR data source with driver: ESRI Shapefile ## Source: &quot;/home/gerardo/Documentos/Cosas ENES/Materias/LCA/Analisis-Modelado-Espacial/Unidad-I/SL-1/LKA_adm1.shp&quot;, layer: &quot;LKA_adm1&quot; ## with 25 features ## It has 14 fields ## Integer64 fields read as strings: ID_0 ID_1 CCN_1 Figura 3.2: Polígono vectorial muestra la isla de Sri Lanka y su división política en distritos. ## OGR data source with driver: ESRI Shapefile ## Source: &quot;/home/gerardo/Documentos/Cosas ENES/Materias/LCA/Analisis-Modelado-Espacial/Unidad-I/Roads/LKA_roads.shp&quot;, layer: &quot;LKA_roads&quot; ## with 500 features ## It has 5 fields Figura 3.3: Capa lineal muestra la red de carreteras principales de la isla de Sri Lanka. 3.1.3.3 Puntos Son conjuntos de coordenadas geográficas (\\(x, y\\)) cartesianas para identificar la localización de un objeto en el espacio. Figura 3.4: Puntos muestran el valor de una medición de alguna variable ambiental en la isla de Sri Lanka. 3.1.3.4 Ejercicio Vuelve a visitar el Socioeconomic Data and Applications Center y clasifica los mapas que seleccionaste anteriormente de acuerdo con el tipo de datos que consideres que contiene cada uno. 3.1.4 ¿Cómo puedo conseguir un SIG? Al igual que con los sistemas operativos (Windows, Mac) y las suites de ofimática (Google Docs, MS Office, Libre Office), existen alternativas tanto comerciales (de pago y código cerrado) como libres (tanto de pago –gratis– como de código fuente). Uno de los SIG más completos que existen es ArcGIS, sin embargo costo de la licencia es bastante alto. PAra evitar la necesidad de pagar licencias, en este curso, utilizaremos QGIS (Quantum GIS), Saga y R, pues son gratuitos y cubren todas las necesidades del curso y muchas más. De hecho, estas herramientas son sumamente competentes tanto para estudiantes como para profesionales que requieren de aplicaciones sofisticadas, por lo que la relación costo-beneficio es insuperable. Para instalar QGIS visita la página web y sigue las instrucciones de instalación para tu sistema operativo. Los demás programas los instalaremos en otra ocasión. 3.2 Modelado espacial El modelado y análisis espacial puede ser tan variado como los tipos de datos y variables que se pueden representar en el espacio. De manera resumida, el modelado espacial es el desarrollo de representaciones espaciales de añgún fenómeno. Los modelos espaciales pueden ser sencillos, producto de operaciones aritméticas entre distintas variables espacializadas, ó de complejos análisis estadísticos. En este curso veremos aplicaciones de ambas, aunque por su utilidad nos enfocaremos más en los análisis estadísticos. Los modelos espaciales pueden estar basados en, o utilizar, datos geográficos de cualquier naturaleza: vectores, puntos o ráster. Los productos de estas diferentes naturalezas, utilizados para construir modelos espaciales pueden provenir de muchas fuentes, incluso ser colectados por nosotrxs mismxs. Las fuentes de información para construir los modelos espaciales dependerán de muchos factores como la extensión geográfica. Para regiones pequeñas es perfectamente factible hacerlo nosotrxs mismos, pero para estudios a mayor escala, debemos utilizar repositorios públicos de información que veremos más adelante. A continuación se muestran algunos ejemplos de procesamiento estadístico. 3.2.1 Datos vectoriales Ejemplos clásicos abundan en la literatura médica, donde típicamente se analiza el número de casos por polígono de alguna enfermedad. Estos análisis consisten, en esencia, de una regresión lineal, donde la variable de respuesta está medida para cada uno de los polígonos de la capa vectorial, y van acompañados de mediciones de alguna(s) variables de respuesta. El ejemplo de abajo, sin embargo es un poco más complicado pues toma en cuenta la similitud entre polígonos vecinos. La escala de colores indica el número de casos por unidad espacial, y esta representación se llama coropleta. Casos de cancer labial en Escocia 3.2.2 Ráster Un tipo de análisis de imágenes ráster muy útil es el desarrollo de mapas de uso de suelo. También existen otras aplicaciones como la estimación de densidad poblacional de humanos a partir de imágenes satelitales. Estimación de densidad poblacional combinando imágenes satelitales y vectoriales 3.2.3 Puntos Un ejemplo de este tipo de análisis es el modelado de nichos ecológicos y áreas de distribución, y consiste en utilizar los datos de puntos para generar un ráster que representa la favorabilidad ambiental para un organismo. Registros de ocurrencia de la serpiente venenosa Bungarus caeruleus y su abundancia potencial estimada en la isla de Sri Lanka 3.2.4 Lecciones El modelado espacial se distingue de otros tipos de modelación en que, mientras los datos pueden representar mediciones de variables no espaciales (temperatura, tamaño de población, tipo de cobertura vegetal), los datos están descritos por su ubicación espacial y tipo de representación en el espacio. En ocasiones es necesario tomar en cuenta dichas descripciones sobre la situación espacial para hacer el análisis debido a la primera ley de la geografía: “Los objetos cercanos son más similares entre sí” A este fenómeno se le conoce como autocorrelación espacial, es decir que una variable con estructura espacial estará correlacionada consigo misma (casi siempre). Por ejemplo en la base de datos de cancer labial, podemos ver que los distritos vecinos tienen niveles de enfermedad más parecidos entre sí. 3.2.4.1 La estructura espacial Cuando decimos que una base de datos está estructurada quiere decir que cada observación tiene un lugar exacto dentro de la base. El ejemplo más sencillo es de una serie temporal, donde los datos están ordenados en relación al tiempo en que fueron colectados, y sus valores también dependen del tiempo (3.5). Figura 3.5: Estructura temporal de una base de datos La repercusión estadística de la estructuración temporal o espacial de los datos es que las observaciones cercanas en el tiempo o espacio no son independientes entre sí. Las observaciones independientes deberían poder tener cualquiera de los valores posibles en la distribución de la variable, pero las observaciones más cercanas tienen valores más parecidos. Por lo tanto es necesario, en muchas ocasiones, utilizar métodos estadísticos que permitan separar esos efectos de la proximidad espacial o temporal de los efectos de otras variables (temperatura, vegetación, etc.). A este fenómeno se le conoce como Autocorrelación espacial o temporal, es decir, que una variable está correlacionada consigo misma. Figura 3.6: Ejemplos de capas ráster con y sin autocorrelación. Los métodos que combinan la modelación estadística y aquellos utilizados para medir y estimar la autocorrelación, son lo que distingue a la modelación estadística de la modelación espacial. 3.2.5 Repositorios públicos gratuitos Áreas administrativas del mundo Clima multidécadas CHELSA Clima multidécadas WorldClim Población y demografía del mundo Socio-economía y aplicaciones Uso de suelo Copernicus (Agencia espacial europea) Características del suelo Ocurrencia de especies GBIF Ocurrencia de especies VertNet Ocurrencia de especies Naturalista Distribución de reptiles y anfibios Sensores remotos "],["unidad-ii-análisis-de-la-asociación-espacial-entre-varios-fenómenos.html", " 4 Unidad II - Análisis de la asociación espacial entre varios fenómenos 4.1 Correlación y regresión espacial 4.2 Análisis de asociación espacial 4.3 Interpolación", " 4 Unidad II - Análisis de la asociación espacial entre varios fenómenos La asociación espacial es el pilar del análisis espacial, y consiste principalmente en medir el grado de dependencia entre dos variables con estructura espacial. 4.1 Correlación y regresión espacial 4.1.1 Correlación espacial La correlación mide la similitud entre dos variables aleatorias, comparando sus varianzas respectivas. Es una prueba muy sencilla, pero que tiene muchas fallas, por ejemplo, no podemos saber si la correlación es causal. Veamos dos ejemplos de correlación entre dos variables ambientales, uno donde hay una alta correlación y otro donde no la hay. Figura 4.1: Variables altamente correlacionadas. Los mapas muestran los valores de dos capas ráster, y la gráfica de dispersión contiene los valores de cada píxel, en el eje x, la variable de la izquieda, y el eje y la variable de la derecha. Figura 4.2: Variables pobremente correlacionadas. Claramente en el ejemplo de la figura 4.1, una de las variables predice a la otra, pero no sabemos cuál produce a cuál, o si ambas sor producidas por otra variable que no se ha medido. En resumidas cuentas, la correlación no se puede utilizar para analizar causalidad, lo cual es común a todos los análisis estadísticos. 4.1.1.1 Breve recordatorio del cálculo de la correlación Como ya han de saber, la correlación es una prueba de estadística frecuentista paramétrica. Como tal, consiste en una serie de cáculos aritméticos para obtener un parámetro \\(r\\): \\[\\begin{equation} r = \\frac{\\sum x_1 x_2}{\\sqrt{\\sum x_1^2 \\sum x_2^2}} \\end{equation}\\] donde \\(x_1\\) y \\(x_2\\) son las dos variables centradas (variable menos la media aritmética), cuya correlación queremos medir. Esta prueba de correlación se llama de Pearson, y existen algunas modificaciones para datos de otra naturaleza como los ordinales, para lo cual se utiliza la correlación de Spearman. El coeficiente de correlación de esta última se denota con \\(\\rho\\). La correlación de Spearman es menos sensible que la de Pearson a correlaciones no lineales, por lo que si la gráfica de las variables \\(x_1, x_2\\) no forma una línea recta como en 4.1, se puede probar con la correlación de Spearman. 4.1.1.2 Correlación en R Medir la correlación entre dos variables espaciales en R es muy fácil, aunque antes de proseguir, debemos aprender a manejar los datos espaciales en R. Como ya han de saber, cuando no podemos hacer algo en R básico, hay que echar un vistazo a las librerías. Las más potentes para manejar datos espaciales son raster y rgdal. La primera, como su nommbre indica, sirve principalmente para imágenes, la segunda, para vectores y puntos. Ambas son compatibles, es decir se pueden hacer procesos espaciales combinando los objetos de R que ambos paquetes utilizan. Vamos a leer un raster con la paquetería raster y la función del mismo nombre: library(raster) r &lt;- raster(&quot;Capas-ejemplo/bio1.tif&quot;) El nombre del achivo es bio1.tif y está contenido en la carpeta “Capas ejemplo.” Para hacer una prueba de correlación, necesitamos leer otra capa: r1 &lt;- raster(&quot;Capas-ejemplo/bio11.tif&quot;) y las vamos a agrupar en un objeto para hacer la prueba de correlación con la función pairs del mismo paquete raster: st &lt;- stack(r, r1) pairs(st) Como podemos ver, la función pairs hace un gráfica con los histogramas de cada variable (en verde), el gráfico de dispersión, y el coeficiente de correlación de Pearson. Vamos a ver entonces qué está haciedo la función pairs Vamos a transformar sl objeto st en una tabla con dos columnas para las coordenadas geográficas de cada píxel y otras dos para los valores de cada variable: t1 &lt;- rasterToPoints(st) t1 &lt;- data.frame(t1) knitr::kable(head(t1)) x y bio1 bio11 -126.1714 59.93903 -34 -208 -126.0047 59.93903 -40 -206 -125.8380 59.93903 -43 -204 -125.6714 59.93903 -41 -202 -125.5047 59.93903 -42 -201 -125.3380 59.93903 -42 -200 Como sabemos el coeficiente de correlación de Pearson utiliza dos cálculos, \\(\\sum x_1 x_2\\) y \\(\\sqrt{\\sum x_1^2 \\sum x_2^2}\\). Vamos a hacerlos a continuación: x1 &lt;- t1$bio1; x2 &lt;- t1$bio11 x1 &lt;- x1-mean(x1); x2 &lt;- x2-mean(x2) calc.1 &lt;- sum(x1 * x2) calc.2 &lt;- sqrt(sum(x1^2) * sum(x2^2)) coef.pearson &lt;- calc.1/calc.2 coef.pearson ## [1] 0.9689097 4.1.2 Regresión La regresión lineal es un procedimiento relativamente similar a la correlación, aunque la principal diferencia está en que la regresión estima parámetros de una ecuación lineal que se puede usar para predicción, y para identificar variables que explican el comportamiento de los datos que hemos colectado o generado. En contraste la correlación sólo nos sirve para ver si dos variables aleatorias se predicen mutuamente, con qué grado de precisión (coeficiente de correlación), y el sentido (positivo o negativo). En una regresión lineal, estimamos una serie de parámetros que corresponden con las constantes de una ecuación lineal: \\[ y(x) = \\alpha + \\beta x \\] donde \\(\\alpha\\) es el intercepto o el valor de \\(y\\) cuando \\(x=0\\), y \\(\\beta\\) es la pendiente de \\(y\\) con respecto de \\(x\\), es decir cuánto cambia \\(y\\) si \\(x\\) aumenta en una unidad. Otro parámetro importante que estimamos en una regresión lineal es \\(r^2\\), y como su nombre lo indica es el cuadrado del coeficiente de correlación \\(r\\). Cuando hacemos modelación estadística, es importante estar al tanto de algunos supuestos. En regresión lineal, estos son algunos importantes: Las observaciones de \\(y\\) son independientes entre sí La relación entre \\(x\\) y \\(y\\) es lineal \\(y\\) tiene una distribución unimodal y con varianza homogénea (igual por arriba y abajo de la media). 4.2 Análisis de asociación espacial A diferencia de las dos secciones anteriores, donde vimos cómo se puede estimar el grado de asociación entre dos procesos espaciales, aquí veremos cómo medir la asociación de una sola variable con el espacio, es decir si ésta variable tiene estructura espacial (autocorrelación). Igual que como hicimos con la prueba de correlación, veamos la fórmula del índice de autocorrelación Moran’s I: \\[\\begin{equation} I = N \\times W \\times \\sum_{i = 1}^n \\sum_{j = 1}^n w_{ij} \\frac{(x_i - \\bar{x})(x_j - \\bar{x})}{\\sum (x_i - \\bar{x})^2} \\end{equation}\\] donde: \\(N\\) es el número total de unidades espaciales indizadas por \\(i\\) y \\(j\\) \\(W\\) es la suma de pesos \\(w_{ij}\\) \\(x\\) es la variable de interés \\(\\bar{x}\\) es la media de \\(x\\) \\(w_{ij}\\) es una matriz de pesos espaciales El índice de Moran toma valores de \\(-1 &gt; I &lt; 1\\), y su interpretación es similar a la del índice de correlación r. De acuerdo con statology: Cuando \\(I = 0\\) significa que la variable espacial tiene una dispersión aleatoria en el espacio: Cuando \\(I = -1\\), la variable espacial tiene una dispesión perfecta en el espacio: Cuando \\(I = 1\\), la variable espacial tiene una agregación espacial perfecta: 4.2.1 Índice de Moran para rasters en R Existen muchas implementaciones del índice de autocorrelación de Moran, el que utilizaremos está en el paquete raster, y utilizaremos una de las capas de las dos clases pasadas, y otras dos que representarán los casos 2 y 3 de arriba. Comenzaremos cargando la capa de la variable ambiental: library(raster) r &lt;- raster(&quot;Capas-ejemplo/Var-1.tif&quot;) plot(r) Moran(r) ## [1] 0.78433 Como podemos ver la capa Var-1 está altamente autocorrelacionada, tanto de manera visible, como estadísticamente. Ahora veamos un caso distinto, creando una capa nueva con valores completamente aleatorios: r1 &lt;- r #Creando el objeto nuevo r1[] &lt;- runif(ncell(r)) #Reemplazando los valores con unos generados aleatoriamente con una distribución uniforme entre 0 y 1 plot(r1) Moran(r1) ## [1] -0.01185495 4.2.2 Índice de Moran para puntos También es posible estimar el índice de Moran para datos de puntos o vectoriales, aunque es necesario construir la matriz de adyacencias espaciales. Haremos este análisis para los datos del primer ejercicio de regresión que hicimos en clase. La matriz de adyacencias es una representación de quién es vecino de quién. Por ejemplo, en la figura ?? el píxel de la esquina superior izquierda es la observación \\(x_{1, 1}\\), y sus vecinas son \\(x_{1, 2}\\) y \\(x_{2, 1}\\), donde \\(i\\) es la fila y \\(j\\) es la columna. Para puntos (figura ??), obtendremos la matriz de adyacencia con base en distancia, de modo que consideraremos vecinos a puntos que estén dentro de una distancia predeterminada. datos &lt;- read.csv(&quot;Datos-ejercicio.csv&quot;) datos$reg &lt;- with(datos, (Mediciones - min(Mediciones))/(max(Mediciones) - min(Mediciones)) + 0.1) with(datos, plot(Longitud, Latitud, cex = reg)) La matriz de adyacencia podemos obtenerla con el paquete spdep(por Spatial Dependence, o dependencia espacial). Para puntos con valores asociados a sus coordenadas geográficas, requiere un par de pasos más: library(spdep) vecindad &lt;- dnearneigh(x = as.matrix(datos[, c(&quot;Longitud&quot;, &quot;Latitud&quot;)]), d1 = 0, d2 = 75, longlat = T) vec.listw &lt;- nb2listw(vecindad) S0 &lt;- sum(nb2mat(vecindad)) I.puntos &lt;- moran.test(x = datos$Mediciones, listw = vec.listw) I.puntos ## ## Moran I test under randomisation ## ## data: datos$Mediciones ## weights: vec.listw ## ## Moran I statistic standard deviate = 9.7604, p-value &lt; 2.2e-16 ## alternative hypothesis: greater ## sample estimates: ## Moran I statistic Expectation Variance ## 0.556186118 -0.010101010 0.003366211 Brevemente, la función dnearneigh crea un objeto que contiene: el número de vecinos de cada punto, con base en el criterio de distancia (0 - 250 km), y la identidad de los vecinos de cada punto (punto 1, 2, 3, etc.). Por alguna razón, este objeto tenemos que representarlo como una lista, que no es otra cosa que una colección de objetos de distinta naturaleza y tamaño, para lo que utilizamos nb2listw (neighbourhood to weights list). Y la última pieza de información que necesitamos es la suma total de pesos espaciales, la cual obtenemos con la suma de los elementos de la matriz con la función nb2mat (neighbourhood to matrix). Finalmente utilizamos la functión moran (del paquete spdep) para obtener el valor del estadístico I. Nota que para rasters utilizamos la función Moran del paquete raster. 4.2.3 Ejemplo de aplicación para análisis de residuales Como se mencionó en el análisis de regresión, el análisis de residuales es esencial en el modelado espacial, pues nos indican si los datos analizados cumplen con el supuesto de independencia. Comenzaremos con el análisis de regresión, cargando los datos obtenidos en campo: datos &lt;- read.csv(string) with(datos, plot(Longitud, Latitud, cex = Mediciones)) y las variables raster para analizar los datos colectados en campo: library(raster) r &lt;- stack(paste0(&quot;Capas-ejemplo/Var-&quot;, c(1, 2), &quot;.tif&quot;)) plot(r) Una vez cargados lo datos, extraemos los valores de ambas variables con las coordenadas donde obtuvimos las mediciones en campo: r.extract &lt;- data.frame(extract(r, datos[, c(&quot;Longitud&quot;, &quot;Latitud&quot;)])) datos &lt;- data.frame(datos, r.extract) Como pueden ver, los datos extraídos los incorporamos al mismo data.frame donde teníamos los datos obtenidos en campo. Este paso, facilitará mucho el manejo de los datos y el llamado de las distintas funciones de R, como la regresión lineal: modelo.1 &lt;- lm(Mediciones ~ Var.2, data = datos) summary(modelo.1) ## ## Call: ## lm(formula = Mediciones ~ Var.2, data = datos) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.5996 -0.5276 0.2858 0.8551 1.9831 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 15.120815 1.115281 13.56 &lt;2e-16 *** ## Var.2 -0.100829 0.009265 -10.88 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.216 on 98 degrees of freedom ## Multiple R-squared: 0.5472, Adjusted R-squared: 0.5426 ## F-statistic: 118.4 on 1 and 98 DF, p-value: &lt; 2.2e-16 Estos resultados ya los conocemos, y muestran que la variable Var.2afecta significativamente a las mediciones que obtuvimos en campo. Ahora entonces tenemos que ver si los residuales se comportan de manera adecuada, primero extrayéndolos y después estimando su asociación con el espacio: datos$Residuales &lt;- residuals(modelo.1) Y proseguimos con el índice de Moran como lo hicimos anteriormente, tanto con las mediciones como con los residuales library(spdep) vecindad &lt;- dnearneigh(x = as.matrix(datos[, c(&quot;Longitud&quot;, &quot;Latitud&quot;)]), d1 = 0, d2 = 75, longlat = T) vec.listw &lt;- nb2listw(vecindad) S0 &lt;- sum(nb2mat(vecindad)) I.meds &lt;- moran.test(x = datos$Mediciones, listw = vec.listw) I.res &lt;- moran.test(x = datos$Residuales, listw = vec.listw) Índice de Moran para las mediciones ## ## Moran I test under randomisation ## ## data: datos$Mediciones ## weights: vec.listw ## ## Moran I statistic standard deviate = 14.18, p-value &lt; 2.2e-16 ## alternative hypothesis: greater ## sample estimates: ## Moran I statistic Expectation Variance ## 0.769152627 -0.010101010 0.003020113 Índice de Moran para los residuales ## ## Moran I test under randomisation ## ## data: datos$Residuales ## weights: vec.listw ## ## Moran I statistic standard deviate = 15.7, p-value &lt; 2.2e-16 ## alternative hypothesis: greater ## sample estimates: ## Moran I statistic Expectation Variance ## 0.852139315 -0.010101010 0.003016244 Lo que sugiere que los residuales están muy agregados. 4.3 Interpolación La interpolación es el proceso de aproximación de los valores en un intervalo en el que sólo conocemos los extremos inferior y superior. Así por ejemplo en el conjunto ordenado de valores: \\[ 1, 3, 5, 7 \\] es posible inferir que los valores intermedios son: \\[ 2, 4, 6 \\] asumiendo que entre cada observación \\(1, 3, 5, 7\\), los valores intermedios se pueda aproximar linealmente. En modelado espacial, la interpolación se utiliza muy frecuentemente para generar capas ráster a partir de mediciones en puntos, como aquellas que utilizamos en correlación y regresión. El fin último de la interpolación es la predecir la variación espacial de los valores de la variable que medimos. Así como rellenamos los valores intermedios en la secuencia \\(1, 3, 5, 7\\) asumiento linealidad, hay muchos otros métodos para predicción de valores ordenados de manera más compleja y en dos dimensiones. Algunas de las técnicas más comunes para predicción espacial son: Vecino más próximo Inverso de la distancia Regresión sobre las coordenadas Splines 4.3.1 Vecino más próximo Este es el método de interpolación más sencillo que existe y consiste en asumir que el valor de los píxeles intermedios es equivalente al mismo valor del píxel más cercano. 4.3.2 Inverso de la distancia (IDW en inglés) Este método asume que los valores de la variable interpolada entre los puntos de referencia cambia en relación directa con la distancia entre los puntos. Por ejemplo, Si tenemos dos mediciones de temperatura separadas físicamente 10 km, y queremos estimar la temperatura en los puntos intermedios con una precisión de 1 km, la temperatura de éstos será proporcional a la diferencie entre las mediciones. Figura 4.3: Interpolación por distancia, los extremos representan los puntos donde fueron obtenidas las mediciones, y los píxeles intermedios fueron rellenados por interpolación. 4.3.3 Regresión sobre las coordenadas Es un método sencillo pero efectivo si la variable que queremos interpolar tiene un gradiente a lo largo de la longitud y/o latitud que se puede aproximar por medio de un modelo lineal. La idea es que la variable de respuesta (\\(y\\)), sea una función lineal de las coordenadas (\\(x_1, x_2\\)): \\[ y(Lat, Lon) = \\alpha + \\beta_1 Lat + \\beta_2 Lon\\] Figura 4.4: Ejemplos de gradientes lineales con las coordenadas. Al igual que con los modelos lineales, este tipo de interpolación puede ser muy flexible, aunque cuando la variable dependiente \\(y\\) es poco lineal con respecto de la latitud y longitud se recomienda usar Splines 4.3.4 Splines Son una metodología muy similar a la regresión por coordenadas pero no asume ningún tipo de relación funcional entre la latitud y longitud y la variable de respuesta. La manera en que funcionan las splines es ajustando líneas de regresión con un polinomio de 2o o 3er grado a porciones específicas de cada variable independiente. El resultado de usar splines pueden ser curvas complejas con un contorno suave. Ejemplo de regresión con splines por Arthur Charpentier 4.3.5 Tutorial de interpolación en R 4.3.5.1 Vecino más cercano Para interpolar con este método necesitamos primero identificar los píxeles más cercanos a los puntos donde tenemos mediciones, para ello, tenemos que crear un teselado de Voronoi en formato vectorial. Comencemos por cargar los datos con las mediciones, y la capa ráster que usaremos de referencia de resolución espacial: library(raster) r &lt;- raster(&quot;Capas-ejemplo/Var-1.tif&quot;) datos &lt;- read.csv(&quot;Datos-ejercicio.csv&quot;) Y proseguimos creando el teselado con la función voronoi del paquete dismo. Debido a que voronoi es la única función de dicho paquete que vamos a usar, evitaremos cargar todo el paquete usando la sintaxis paquete::función. vo &lt;- dismo::voronoi(datos) plot(vo, main = &quot;Teselado de Voronoi&quot;) points(datos$Longitud, datos$Latitud, pch = 20, col = &quot;red&quot;) Figura 4.5: Teselado de Voronoi para los puntos de muestreo (en rojo). Nota cómo hay un polígono del teselado para cada punto, las vecindades se establecen con base en los polígonos que comparten frontera. Después, para obtener el raster interpolado, tenemos que asignar el valor de cada punto a los polígonos del teselado, y rasterizarlo a la resolución del ráster de referencia. Comenzamos creando un ráster con valores de cero (\\(0\\)), que usaremos para acotar el teselado, pues tiene una extensión mayor a la que nos interesa: r.0 &lt;-r r.0[] &lt;- 0 r.vec &lt;- rasterToPolygons(r.0, dissolve = T) ## Loading required namespace: rgeos vo &lt;- intersect(vo, r.vec) #Recorte del teselado plot(vo, main = &quot;Teselado recortado&quot;) points(datos$Longitud, datos$Latitud, pch = 20, col = &quot;red&quot;) Ahora, asignamos los valores de las mediciones a cada polígono y lo rasterizamos asignando a los píxeles del raster de referencia los valores de cada polígono: vo$Mediciones &lt;- datos$Mediciones r.ngb &lt;- rasterize(vo, r.0, field = &quot;Mediciones&quot;) plot(r.ngb, main = &quot;Mediciones interpoladas&quot;) plot(vo, add = T) points(datos$Longitud, datos$Latitud, pch = 20, col = &quot;red&quot;) Figura 4.6: Resultado de la interpolación por vecino más cercano. En este procedimiento asignamos a todos los píxeles que quedan dentro de cada polígono el mismo valor. 4.3.5.2 Inverso de la distancia La función básica de interpolación en R es interpolate del paquete raster. Para aprender a utilizarla podemos hacer una búsqueda rápida en la ayuda de R: ?raster::interpolate Y vemos que los argumentos mínimos que necesitamos son: Objeto raster Modelo El Objeto raster se refiere a una capa que será utilizada como referencia de resolución y extensión espacial para interpolar, y Modelo es el procedimiento de interpolación que se utilizará (vecino más cercano, etc.). La mayoría de los modelos de interpolación podemos encontrarlos en el paquete gstat. Para interpolar utilizaremos las mismas bases de datos de antes. Antes de la interpolación, es necesario formatear de manera especial los datos. La base que contiene la localidades de muestreo y las mediciones, tenemos que transformarla en un objeto reconocible por el paquete sp, de modo que sepa qué columnas contienen las coordenadas \\(x, y\\), y cuáles los datos: library(gstat) datos.sp &lt;- datos coordinates(datos.sp) &lt;- ~ Longitud + Latitud proj4string(datos.sp) &lt;- CRS(proj4string(r.0)) Y hacemos lo mismo con el ráster de referencia, primero transformándolo en data.frame y luego en SpatialPointsDataFrame: new.data &lt;- data.frame(rasterToPoints(r.0))[, 1:2] names(new.data) &lt;- c(&quot;Longitud&quot;, &quot;Latitud&quot;) coordinates(new.data) &lt;- ~ Longitud + Latitud proj4string(new.data) &lt;- CRS(proj4string(r.0)) Nota que en ambos casos anteriores tuvimos que especificar qué sistema de coordenadas se usó, en este caso fue el datum WGS84 con número de identificación EPSG 4326. Y ahora sí, corremos la rutina de interpolación con la función idw (inverse distance weighted) de gstat. inv.dist &lt;- idw(formula = Mediciones ~ 1, locations = datos.sp, newdata = new.data) ## [inverse distance weighted interpolation] El objeto que produce la función idw es un SpatialPolygonsDataFrame (vector poligonal), donde cada celda corresponde a un píxel. Para transformar a raster utilizaremos las coordenadas de new.datay los valores interpolados con la función rasterFromXYZ: r.idw &lt;- rasterFromXYZ(data.frame(coordinates(new.data), inv.dist$var1.pred)) #Gráfica par(mfrow = c(1, 2)) plot(r.idw, main = &quot;Inverso de la distancia&quot;) plot(r.idw) points(datos.sp, pch = 20, col = &quot;red&quot;, cex = 0.5) Figura 4.7: Interpolación por inverso de la distancia. Como podemos ver el resultado de la interpolación con vecino más cercano es muy diferente de inverso de la distancia. ¿Qué artefacto puedes detectar? 4.3.6 Regresión de las coordenadas con splines En esta ocasión nos retringiremos a revisar estos métodos en conjunto pues las ocasiones en que podríamos detectar gradientes perfectos como en la figura 4.4 son muy escasos. En la inmensa mayoría existirán estructuras topográficas en el espacio que harán que las relaciones entre lo que medimos y las coordenadas geográficas sean no lineales. Por lo tanto, la herramienta más útil son los splines. La implementación más sencilla de splines para usar en R son los modelos lineales aditivos. Para estos análisis podemos utilizar todos los objetos que ya formateamos hasta ahora. Las funciones para ajustar modelos lineales aditivos están en el paquete mgcv, instalado por defecto con R, en la función gam (generalised additive model). Por defecto, las fórmulas que se usan en gam son idénticas a las que se usan en lm (modelo lineal). Para que una variable pueda incorporar no-linealidades, necesitamos espacificar el tipo de splines que se utilizarán con otras funciones. Veamos: library(mgcv) spl &lt;- gam(Mediciones ~ s(Longitud, Latitud, k = 25), data = datos) donde s es la función suavizadora o spline, y k es el número de nodos que habrá en cada variable. Yo decidí arbitrariamente utilizar 25 nodos, pero en realidad puede haber objetivamente más o menos nodos. Los nodos son puntos igualmente espaciados en el rango de valores de cada variable en los cuales se estimarán parámetros del spline. Por ejemplo, para Longitud -100 – -101, un parámetro, y otro para -101 – -102. Para ver las predicciones de gam: spl.pred &lt;- predict(spl, newdata = data.frame(coordinates(new.data))) r.spl &lt;- rasterFromXYZ(data.frame(coordinates(new.data), spl.pred)) plot(r.spl, main = &quot;Interpolalción con splines&quot;) points(datos.sp, pch = 20, col = &quot;red&quot;, cex = 0.5) Figura 4.8: Resultado de la interpolación con splines en un modelo aditivo generalizado, haciendo regresión sobre las coordenadas Otra implementaciín de splines, incluso más adecuada para la interpolación espacial, se llama Thin Plate Spline, disponible con la función Tps en el paquete fields. 4.3.7 Otros tipos de interpolación Bicúbico Bilineal Kriging Regresión-Kriging "],["unidad-iii-aplicaciones-del-modelo-digital-de-elevación.html", " 5 Unidad III - Aplicaciones del modelo digital de elevación 5.1 Desarrollo de un modelo digital de elevación 5.2 Cálculo de parámetros morfométricos 5.3 Modelado hidrológico", " 5 Unidad III - Aplicaciones del modelo digital de elevación 5.1 Desarrollo de un modelo digital de elevación Un modelo digital de elevación es un a representación ráster de la elevación sobre el nivel del mar de la superficie terrestre. La información sobre la elevación es muy importante para el análisis del clima, topografía e hidroligía. En climatología, la elevación está muy relacionada con las temperaturas y las lluvias. En topografía, la elevación se puede utiizar para encontrar la inclinación o pendiente de un terreno, el aspecto, o dirección de la inclinación y capacidad para almacenar agua. En hidrología la elevación se puede utilizar para estimar el tamaño potencial de los cuerpos de agua, la velocidad o fuerza con que puede descender el agua de una montaña, identificar ríos y zonas inundables. La aplicaciones del modelo digital de elevación en topografía e hidrología se conoce como Geomorfología. Figura 5.1: Modelo digital de elevación Los modelos digitales de elevación, además de contener explícitamente información sobre la altura promedio por píxel, contienen información sobre elementos del paisaje, como la presencia de ríos. De hecho para el desarrollo de modelos digitales de elevación puede llegar a utilizarse dicha información. Los modelos digitales de elevación pueden ser desarrollados tanto por medio de interpolación, como por el análisis y procesamiento de imágenes satelitales. El sensor remoto utilizado para los modelos digitales de elevación es el Shuttle Radar Topography Mission (SRTM), y sus productos están disponbles libres de costo al público en general con una resolución de 30m (¡treinta metros!). Para la creación de modelos digitales de elevación de mayor resolución se necesita utilizar otras metodologías, combinando interpolación de puntos y datos vectoriales (de ríos, viviendas p. ej.). 5.1.1 Tutorial de desarrollo de MDE Este tutorial consiste de la interpolación de unos puntos con mediciones de elevación en QGIS (el tutorial original es parte de una capacitaicón en QGIS). Además de la interpolación, vamos a utilizar una capa de ríos para dotar de información topográfica a las interpolaciones. Los datos del tutorial los encuentras en esta liga. Los datos disponibles son: Puntos con mediciones de altura Líneas de ríos/riachuelos Líneas de ruptura-contorno El modelo de interpolación que permite interpolar a partir de estas estructuras se llama TIN (triangular irregular networks). Comencemos abriendo todas las capas en QGIS (todas en la misma ventana). En el panel de Caja de procesos, buscamos TIN, y damos doble click para ver la siguiente ventana: vamos a comenzar simplemente interpolando las mediciones de elevación de los puntos. Y después interpolaremos con las curvas y finalmente con los ríos, para comparar los resultados. Para interpolar con los puntos, líneas o curvas, seleccionamos la capa que utiizaremos para interpolar del menú Capa Vector, y luego la columna de datos de esa capa que interpolaremos. En la caja de abajo, tenemos que añadir si la capa se utilizará como puntos, líneas de estructura o de ruptura, o como todas ellas. Posteriormente seleccionamos si el método de interpolación será lineal o Clough-Toucher (produce cambios más suaves que lineal). Finalmete seleccionamos la extensión espacial a partir de una de las capas vectoriales que tenemos abiertas y la resolución (no de píxeles en filas y columnas). 5.2 Cálculo de parámetros morfométricos 5.3 Modelado hidrológico "],["unidad-iv.html", " 6 Unidad IV", " 6 Unidad IV "],["unidad-v.html", " 7 Unidad V", " 7 Unidad V "],["unidad-vi.html", " 8 Unidad VI", " 8 Unidad VI "],["references.html", "References", " References "]]
